{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de4f6fba-76ad-480f-beed-e2b4ae2a407a",
   "metadata": {},
   "source": [
    "# Enhancing GFM derived flood maps with Digital Terrain Models\n",
    "We use the FLEXTH algorithm developed by the Joint Research Centre of the European Commission together with the FABDEM, a Digital Terrain Model, at a spatial resolution of 30m to enhance flood maps from the Global Flood Monitoring Database. This notebook features the code for the recommended practice by UN-SPIDER, accessible here.\n",
    "\n",
    "The script is devided into four sections:\n",
    "1. Loading necessary libraries.\n",
    "2. Specifing user specific input and output directories.\n",
    "3. Selecting the AOI and DTM source.\n",
    "4. Setting further Parameters\n",
    "5. Mosaicing and Reprojecting GFM outputs.\n",
    "6. FLEXTH\n",
    "\n",
    "# 1. Loading the Libraries\n",
    "The following cell should be tested before the flood, after setting up your environment \"flexth_env\" with miniforge3 and mamba. See therefore the documentation in the recommended practice. If it can be executed without any error messages, you are prepared for deriving enhanced flood maps, in case of disaster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe874e3c-d403-4dda-af6e-58549ffd15b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from osgeo import gdal\n",
    "import glob, os\n",
    "import logging\n",
    "import rasterio\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "from rasterio.merge import merge\n",
    "from rasterio.mask import mask\n",
    "from rasterio.plot import show\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "from astropy.convolution import convolve\n",
    "import warnings\n",
    "import time\n",
    "from scipy.spatial import cKDTree\n",
    "import geopandas as gpd \n",
    "from shapely.geometry import box \n",
    "from matplotlib import pyplot\n",
    "\n",
    "gdal.UseExceptions()\n",
    "\n",
    "print('Libraries loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53f567c-dab2-4fd6-aad0-86b21b8ceee1",
   "metadata": {},
   "source": [
    "# 2. Specifing input and output directories\n",
    "The input directory is the downloaded and unziped! Folder from GFM. It makes sence to store it in a designated directory and not in your Downloads Folder. GFM has a naming convention for their downloads, which is nameofyouraoi_YYYY-MM-DDT00_hh_mm_YYYY_MM_DDTHH_MM_SS_....\n",
    "It makes sence to store the output folder in the same directory. Please create it before running the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91b00640-2f0a-410d-888a-a2510d777e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unziped Download Folder from GFM:\n",
    "input_dir = Path(r'C:/UrbanFloods/SriLanka/input_gfm/') \n",
    "output_dir = Path(r'C:/UrbanFloods/SriLanka/output/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8a194e5f-f88c-489b-ba57-522c6cc9aedd",
   "metadata": {},
   "source": [
    "# 3. Selecting AOI and DTM sources\n",
    "## AOI\n",
    "You can specify an AOI in form of a geopackage (.gpkg) or a shapefile (.shp) in order not to run FLEXTH for the entire Sentinel-1 scene. The inputs and outputs will then be cropped to your AOI. If you don't have an AOI please write instead of the path to your roi, None.\n",
    "\n",
    "## DTM\n",
    "Other than for the AOI, without a DTM, the code won't work. Specify the path to your dtm in the variable dtm_path. It should be a .tif, for example the FABDEM, which we downloaded with the Google Earth Engine during the first steps of this practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efcba850-7990-4899-8d89-c94be7051471",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_path = \"C:/UrbanFloods/srilanka/fabdem_srilanka.tif\" # .tif\n",
    "roi_path = \"C:/UrbanFloods/srilanka/srilanka_roi.gpkg\" # .gpkg or .shp\n",
    "dst_crs  = None # if 'None' rasters will be reprojected into EPSG:3857\n",
    "\n",
    "if dtm_path == None:\n",
    "    print('Please specify the path to your DTM before continuing.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e2402e95-b553-47a8-82d6-8d60e9af8ed7",
   "metadata": {},
   "source": [
    "# 4. Setting further Parameters\n",
    "## Likelihood vs. Flood Layer\n",
    "GFM also provides a likelihood layer, in which pixels are assigned a likelihood of flooding. Detailed documentation on how these values are calculated is provided here.\n",
    "This is useful in case there are not enough pixels classified as flooded in the Observed Flood Extent Layer. In that case this layer is thresholded with a likelihood threshold (likelihood_thr). Default is 40%, which means pixels with a likelihood > 40% are considered as flooded. \n",
    "\n",
    "## Tiling\n",
    "If your AOI is big, or the computational capacity of your machine is low, it is recommended to tile the inputs and outputs. This is for example relevant if you don't specify an AOI. The size of these tiles in number of pixels is set in param_tile_size. \n",
    "\n",
    "## Hydrological Parameters\n",
    "A detailed explanation of the following parameters is given in the publication by Betterle and Salamon (2024) https://doi.org/10.5194/nhess-24-2817-2024. Brief explanations are also given in the recommended practice. Testing showed, that the default values are effective and robust in a wide range of settings. Nonetheless, parameters can be tweaked to mach specific needs and/or use cases. If the spatial resolution of the flood map is much larger/smaller than 10m, parameters may require adjustments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd7956d1-f46a-41ad-8bb7-48edd0c4e840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likelihood Layer will be thresholded with 40%.\n"
     ]
    }
   ],
   "source": [
    "likelihood = True # True, if likelihood layer should be used as flood layer\n",
    "likelihood_threshold = 40 # in Percent\n",
    "\n",
    "if likelihood == True:\n",
    "    print('Likelihood Layer will be thresholded with ' + str(likelihood_threshold) + '%.')\n",
    "\n",
    "param_tiling      = False    # True to run FLEXTH on the tiled inputs\n",
    "param_tile_inputs = True     # True to tile the inputs. If input is already tiled, select False. Relevant if \"param_tiling = True\"\n",
    "param_tile_size   = 20000    # size of the squared tiles (pixels)\n",
    "\n",
    "\n",
    "# Water level estimation method (options: 'method_A', 'method_B'): \n",
    "param_WL_estimation_method = 'method_A'  \n",
    "\n",
    "# Select output: Water depth (\"WD\") , Water level (\"WL\"), both (\"WL_WD\")\n",
    "param_output_map = \"WL_WD\"\n",
    "\n",
    "# Parameters\n",
    "param_threshold_slope           =  0.2     # S_max : border pixels steeper than this (D_z/D_x) are not used to estimate water level\n",
    "param_size_gaps_close           =  0.05    # A_g   : up to this size (in km2) gaps in the flood map will be closed\n",
    "\n",
    "param_border_percentile         =  0.5     # P: assign water level based on the percentile P of the elevation of border cells (valid if Method B is selected)\n",
    "param_max_number_neighbors      =  100     # N_max: number of border pixels used to compute water level at a single location\n",
    "param_min_flood_size            =  10      # N_min: if the number of valid pixels along the border is less than this, WL is estimated based on the distribution of the elevation of the pixels inside the flooded area\n",
    "param_inner_quantile            =  0.98    # P*: for  flooded areas that don't meet the criteria above, uses this percentile of the elevation of the pixels inside the flooded area to estimate water levels\n",
    "param_inverse_dist_exp          =  1       # alpha: inverse distance weighting exponent used to interpolate WL inside flooded areas \n",
    "\n",
    "\n",
    "param_max_propagation_distance  =  10    # D_max: maximum propagation distance in km\n",
    "param_distance_range            =  5     # A_1/2: flooded areas of this size (km2) reach half of the maximum propagation distance  \n",
    "\n",
    "param_WD_star                   =  10    # WD*: dummy water depth in cm assigned if estimated WL<DTM in initially delineated flooded areas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95369951-54c9-4826-9944-688599ddb5d2",
   "metadata": {},
   "source": [
    "# 5. Mosaicing and Reprojecting GFM outputs\n",
    "GFM outputs flood, permanent water body layers and exclusion masks in tiles and in latitude longitude coordinates. To clip the outputs to the AOI, and to run FLEXTH, the layers have to be one tif each, and need to be in a projected coordinate system. Therefore, all the layers are first mosaiced, then the flood layer is cropped and reprojected. The other layers and the dtm are then projected into the same grid.\n",
    "\n",
    "You need to run this cell only once. If you change something concerning the parameters, you do not need to run this again. But if your AOI changes, please run it again. Therefore, you need to delete the older datasets first, as the script does not overwrite them automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db29a8d7-117f-4379-a597-e8ca3f590379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likelihood Layer successfully thresholded.\n",
      "Flood Layer is clipped to AOI...\n",
      "Flood Layer reprojected.\n"
     ]
    }
   ],
   "source": [
    "def mosaic_tiles(input_dir, pattern):\n",
    "    id = pattern.split('_')[1].split('*')[0]\n",
    "    q = os.path.join(input_dir, pattern)\n",
    "    flood_rst = glob.glob(q)\n",
    "    \n",
    "    rst_lst = []\n",
    "    \n",
    "    for fp in flood_rst:\n",
    "        src = rasterio.open(fp)\n",
    "        rst_lst.append(src)\n",
    "        \n",
    "    mosaic, out_trans = merge(rst_lst)\n",
    "    \n",
    "    out_meta = src.meta.copy()\n",
    "    out_meta.update({\"driver\": \"GTiff\",\n",
    "                    \"height\": mosaic.shape[1],\n",
    "                    \"width\": mosaic.shape[2],\n",
    "                     \"transform\": out_trans,\n",
    "                     \"crs\": src.crs\n",
    "                     }\n",
    "                  )\n",
    "    \n",
    "    with rasterio.open(str(input_dir) + '/' + id +'_mosaic.tif', \"w\", **out_meta) as dest:\n",
    "        dest.write(mosaic)\n",
    "\n",
    "# File Path Patterns\n",
    "lyr_ids = ['*ENSEMBLE_UNCERTAINTY*.tif', '*ENSEMBLE_EXCLAYER*.tif', '*ENSEMBLE_OBSWATER*.tif', '*ENSEMBLE_FLOOD*.tif']\n",
    "\n",
    "# Mosaicing\n",
    "for i in range(len(lyr_ids)):\n",
    "    mosaic_tiles(input_dir, lyr_ids[i])\n",
    "\n",
    "\n",
    "#%% Reprojections\n",
    "\n",
    "# check if mosaics are already in the folder\n",
    "\n",
    "# Checkpoint for Reprojections - if they are even necessary.\n",
    "if dst_crs == None:\n",
    "    dst_crs = 'EPSG:3857'\n",
    "\n",
    "# Threshold the Uncertainty layer\n",
    "if likelihood == True:\n",
    "    with rasterio.open(str(input_dir) + '/' + 'UNCERTAINTY_mosaic.tif') as src:\n",
    "        rst = src.read(1)\n",
    "        likelihood_thr = (rst > likelihood_threshold).astype(np.uint8) \n",
    "        nodata = src.nodata\n",
    "        likelihood_thr[rst == nodata] = nodata\n",
    "    \n",
    "        out_meta = src.meta.copy()\n",
    "        out_meta.update(dtype=rasterio.uint8)\n",
    "\n",
    "        with rasterio.open(str(input_dir) + '/' + 'Likelihood_thr.tif', \"w\", **out_meta) as dst:\n",
    "            dst.write(likelihood_thr, 1)\n",
    "    \n",
    "    input_flood_delineation = input_dir / 'Likelihood_thr.tif'\n",
    "    print('Likelihood Layer successfully thresholded.')\n",
    "    \n",
    "else:\n",
    "    input_flood_delineation = input_dir / 'FLOOD_mosaic.tif'\n",
    "\n",
    "# reproject the flood raster\n",
    "with rasterio.open(input_flood_delineation) as src:\n",
    "    transform, width, height = calculate_default_transform(\n",
    "        src.crs, dst_crs, src.width, src.height, *src.bounds)\n",
    "    kwargs = src.meta.copy()\n",
    "    raster_bounds = src.bounds\n",
    "    kwargs.update({\n",
    "        'crs': dst_crs,\n",
    "        'transform': transform,\n",
    "        'width': width,\n",
    "        'height': height\n",
    "    })\n",
    "    output_filename = \"flood.tif\" if roi_path is None else \"flood_reproj.tif\"\n",
    "    with rasterio.open(str(input_dir) + '/' + output_filename, 'w', **kwargs) as dst:\n",
    "        for i in range(1, src.count + 1):\n",
    "            reproject( \n",
    "                source=rasterio.band(src, i),\n",
    "                destination=rasterio.band(dst, i),\n",
    "                src_transform=src.transform,\n",
    "                src_crs=src.crs,\n",
    "                dst_transform=transform,\n",
    "                dst_crs=dst_crs,\n",
    "                resampling=Resampling.nearest)\n",
    "    \n",
    "# Crop the flood raster to the ROI\n",
    "if roi_path != None:\n",
    "    print('Flood Layer is clipped to AOI...')\n",
    "    roi = gpd.read_file(roi_path)\n",
    "    roi_reproj = roi.to_crs(dst_crs) \n",
    "    \n",
    "    with rasterio.open(str(input_dir) + '/' + 'flood_reproj.tif') as src:\n",
    "        raster_bounds = src.bounds\n",
    "        raster_gdf = gpd.GeoDataFrame({\"geometry\": [box(*raster_bounds)]}, crs = dst_crs)\n",
    "        roi_crp = gpd.clip(roi_reproj, raster_gdf) # has to be cropped to the extent of the input rasters\n",
    "        \n",
    "        # checkpoint if roi intersects the mosaic\n",
    "        if roi_crp.empty:\n",
    "            raise ValueError(\"The AOI is empty. Please check the input AOI file.\")\n",
    "            \n",
    "        out_image, out_transform = mask(src, roi_crp.geometry, crop = True)\n",
    "        \n",
    "        out_meta = src.meta.copy()\n",
    "        out_meta.update({\n",
    "            \"driver\": \"GTiff\",\n",
    "            \"height\": out_image.shape[1],\n",
    "            \"width\": out_image.shape[2],\n",
    "            \"transform\": out_transform\n",
    "            })\n",
    "        with rasterio.open(str(input_dir) + '/' + 'flood.tif', \"w\", **out_meta) as dst:\n",
    "            dst.write(out_image)\n",
    "\n",
    "print('Flood Layer reprojected.')\n",
    "\n",
    "#%%\n",
    "flood_dataset = rasterio.open(str(input_dir) + '/' + 'flood.tif')\n",
    "flood_array   = flood_dataset.read(1)\n",
    "\n",
    "transform = flood_dataset.transform\n",
    "flood_array_nrows, flood_array_ncol =  flood_array.shape\n",
    "Dx= transform[0]\n",
    "Dy= transform[4]\n",
    "minX= transform[2]\n",
    "maxY= transform[5]\n",
    "maxX= minX + Dx*flood_array_ncol\n",
    "minY= maxY + Dy*flood_array_nrows\n",
    "\n",
    "proj = flood_dataset.crs.wkt\n",
    "outputBounds=[minX, minY, maxX, maxY]\n",
    "\n",
    "# function to reproject all input rasters other than the input flood delineation\n",
    "def reproj(input_path, output_path, proj, outputBounds, continuous_input = True):\n",
    "    \n",
    "    raster_dataset = rasterio.open(input_path)\n",
    "    input_proj       = raster_dataset.crs.wkt\n",
    "    output_proj      = proj\n",
    "\n",
    "    if continuous_input == True:\n",
    "        resampling_method = 'bilinear'# other options: 'average', 'cubic', 'lanczos' ... \n",
    "    elif continuous_input == False:\n",
    "        resampling_method = 'mode'   # other options: 'nearest' ...\n",
    "    \n",
    "    gdal.Warp(str(output_path), \n",
    "              str(input_path), \n",
    "              outputBounds=outputBounds,\n",
    "              cropToCutline    = True,\n",
    "              outputBoundsSRS = output_proj, \n",
    "              warpMemoryLimit= 5000,\n",
    "              srcSRS= input_proj, \n",
    "              dstSRS= output_proj, \n",
    "              xRes=Dx,\n",
    "              yRes=Dy, \n",
    "              resampleAlg= resampling_method,\n",
    "              targetAlignedPixels = False,\n",
    "              creationOptions = [\"COMPRESS=ZSTD\", \"BIGTIFF=YES\", \"TILED=YES\"]    # compression options: ZSTD, DEFLATE, LZW\n",
    "              )\n",
    "    \n",
    "    #flood_dataset.close()\n",
    "    raster_dataset.close()\n",
    "\n",
    "reproj(dtm_path, input_dir / 'dtm.tif', proj, outputBounds, continuous_input = True)\n",
    "reproj(input_dir / 'EXCLAYER_mosaic.tif', input_dir / 'exclusion.tif', proj, outputBounds, continuous_input = False)\n",
    "reproj(input_dir / 'OBSWATER_mosaic.tif', input_dir / 'obswater.tif', proj, outputBounds, continuous_input = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9c119f-f935-4cc3-a810-8e9be9740b60",
   "metadata": {},
   "source": [
    "# 6. FLEXTH\n",
    "Now we are finally ready to run FLEXTH. FLEXTH takes the input rasters: 'flood.tif', 'exclusion.tif', 'dtm.tif', 'obswater.tif' in the input_dir and propagates water into the masked areas.\n",
    "After it has finished, you will find the output in the folder you specified earlier. Depending on which method you used, the file name will either start with WL for Water Level or WD for Water Depth.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "754a2454-81e2-48ae-b7b2-1b38a1de837d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing small gaps in flood map...\n",
      "Assigns water elevation to initial flooded areas\n",
      "Augmenting flooded areas...\n",
      "Smoothing... \n",
      "\n",
      "Saving \n",
      "\n",
      "Finish \n",
      "\n",
      "Total processing time:0 minutes\n"
     ]
    }
   ],
   "source": [
    "#######################################################################################\n",
    "## END INPUT - No need to modify anything after this point (unless you have good ideas)\n",
    "#######################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##############\n",
    "#FUNCTIONS######\n",
    "##################\n",
    "\n",
    "#tiles and input_raster raster into output_dir\n",
    "def tiling(input_raster, source_dir, param_tile_size):\n",
    "    from rasterio.windows import Window\n",
    "    \n",
    "    file_name = os.path.splitext(os.path.basename(input_raster))[0]\n",
    "    \n",
    "    output_folder = source_dir / 'input_tiled'\n",
    "    \n",
    "    \n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    \n",
    "    # Open the GeoTIFF file\n",
    "    with rasterio.open(input_raster) as src:\n",
    "        # Get the raster size\n",
    "        rastersize_width, rastersize_height = src.width, src.height\n",
    "    \n",
    "    \n",
    "        # Calculate the number of tiles in x and y directions\n",
    "        num_tiles_x = (rastersize_width  + param_tile_size - 1) // param_tile_size\n",
    "        num_tiles_y = (rastersize_height + param_tile_size - 1) // param_tile_size\n",
    "    \n",
    "    \n",
    "        # Loop through each tile and extract it from the original raster\n",
    "        for i in range(num_tiles_x):\n",
    "            for j in range(num_tiles_y):\n",
    "                # Calculate the tile's bounding box\n",
    "                x_off = i * param_tile_size\n",
    "                y_off = j * param_tile_size\n",
    "                x_size = min(param_tile_size, rastersize_width  - x_off)\n",
    "                y_size = min(param_tile_size, rastersize_height - y_off)\n",
    "    \n",
    "                # Create a window object for the tile\n",
    "                window = Window(x_off, y_off, x_size, y_size)\n",
    "    \n",
    "                # Read the tile from the original raster\n",
    "                tile_data = src.read(1, window=window)\n",
    "    \n",
    "                # Create a new GeoTIFF file for the tile\n",
    "                tile_profile = src.profile\n",
    "                tile_profile.update({\n",
    "                    'width': x_size,\n",
    "                    'height': y_size,\n",
    "                    'transform': rasterio.windows.transform(window, src.transform),\n",
    "                    'compress': 'deflate'\n",
    "                })\n",
    "                with rasterio.open(output_folder/f'{file_name}_tile_{i+1}_{j+1}.tif', 'w', **tile_profile) as dst:\n",
    "                    dst.write(tile_data, 1)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "#  identifies the indices of neighboring cells in an array \n",
    "#  i,j : indices of the target location; \n",
    "#  n_row and n_col:  number or rows and columns of the  target array \n",
    "#  connectivity: type of connectivity to use (4 , 8)\n",
    " \n",
    "def ij_neighbors(i,j,n_row,n_col,connectivity):  \n",
    "    if connectivity == 4:\n",
    "        neighbors=np.array([ [i-1,j], [i,j+1], [i+1,j],  [i,j-1]])    \n",
    "    elif connectivity == 8:\n",
    "        neighbors=np.array([[i-1,j-1],[i-1,j], [i-1,j+1], [i,j+1], [i+1,j+1], [i+1,j], [i+1,j-1], [i,j-1]])  \n",
    "    elif connectivity == 24:\n",
    "        neighbors=np.array([[i-2, j-2],[i-2, j-1], [i-2,j], [i-2,j+1], [i-2,j+2], [i-1, j-2], [i-1,j-1], [i-1,j], [i-1,j+1], [i-1,j+2], [i,j-2], [i,j-1], [i,j+1], [i,j+2], [i+1,j-2], [i+1,j-1], [i+1,j], [i+1,j+1],[i+1,j+2],[i+2,j-2],[i+2,j-1], [i+2,j], [i+2,j+1], [i+2,j+2]  ]     ) \n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported connectivity value: {connectivity}\")\n",
    "    \n",
    "        \n",
    "    for indice in range(len(neighbors)):\n",
    "        if neighbors[indice,0]> n_row-1 or neighbors[indice,0]<0 :\n",
    "            neighbors[indice,0]=i\n",
    "            neighbors[indice,1]=j\n",
    "        if neighbors[indice,1]> n_col-1 or neighbors[indice,1]<0 :\n",
    "            neighbors[indice,0]=i\n",
    "            neighbors[indice,1]=j                     \n",
    "            \n",
    "    return neighbors.astype('uint32')    \n",
    "   \n",
    "    \n",
    "\n",
    "\n",
    "# function that computes the weighted quantiles out of a PDF\n",
    "def weighted_quantile(values, percentile, weights=None):\n",
    "    \"\"\" Very close to numpy.percentile, but supports weights.\n",
    "    NOTE: \n",
    "    :computes one percentile across the columns of a 2d array\n",
    "    :percentile should be in [0, 1]!\n",
    "    :param values: numpy.array with data\n",
    "    :param percentile: the value of the quantile\n",
    "    :param sample_weight: array-like of the same length as `array`\n",
    "    :return: numpy.array with computed percentile for each row of data.\n",
    "    \"\"\"\n",
    "    values = np.array(values)\n",
    "    percentile = np.array(percentile)\n",
    "    if weights is None:\n",
    "        weights= np.ones(np.shape(values))\n",
    "    weights = np.array(weights)\n",
    "    assert np.all(percentile >= 0) and np.all(percentile <= 1), \\\n",
    "        'percentile should be in [0, 1]'\n",
    "\n",
    "\n",
    "    sorter = np.argsort(values)\n",
    "    values = np.take_along_axis(values, sorter, axis = 1)   \n",
    "    weights = np.take_along_axis(weights, sorter, axis = 1)      \n",
    "\n",
    "    weighted_quantiles = np.cumsum(weights, axis = 1 ) - 0.5 * weights\n",
    "\n",
    "    weighted_quantiles /= np.sum(weights, axis = 1)[:, np.newaxis] * np.ones ( np.shape(weighted_quantiles))\n",
    "    \n",
    "    \n",
    "    return values [np.array( np.arange(0,np.shape(values)[0],1)  ), np.argmin( (weighted_quantiles - percentile  )**2, axis = 1) ] \n",
    "\n",
    "\n",
    "##################\n",
    "##################\n",
    "# main function ##\n",
    "##################\n",
    "##################\n",
    "\n",
    "def flood_processing(flood_path, dtm_path, exclusion_path, obswater_path, permanent_water_path):\n",
    "       \n",
    "    flood_georeferenced  =   rasterio.open(  flood_path )\n",
    "    flood                =   rasterio.open(  flood_path ).read(1).astype('uint8')\n",
    "    dtm                  =   rasterio.open(  dtm_path   )\n",
    "    dtm_nodata           =   dtm.nodata\n",
    "    dtm                  =   dtm.read(1)\n",
    "    \n",
    "    dtm[dtm == dtm_nodata]  = np.nan\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #   checks if optional inputs are provided:\n",
    "    # - exclusion mask : areas masked from flood mapping\n",
    "    # - observed water : flood water + permanent waters\n",
    "    # - permanent water: permanent and/or seasonal water bodies\n",
    "    \n",
    "    if os.path.isfile(exclusion_path):\n",
    "        exclusion      =  rasterio.open(  exclusion_path ).read(1).astype('uint8')\n",
    "    else:\n",
    "        exclusion      = np.full_like(flood, 0)\n",
    "        \n",
    "        \n",
    "    if os.path.isfile(obswater_path):\n",
    "        obswater      =  rasterio.open(  obswater_path ).read(1).astype('uint8')\n",
    "    else:\n",
    "        obswater      =  np.copy(flood)\n",
    "    \n",
    "    \n",
    "    if os.path.isfile(permanent_water_path):\n",
    "        permanent_water      =  rasterio.open(  permanent_water_path ).read(1).astype('uint8')\n",
    "    else:\n",
    "        permanent_water      =  np.full_like(flood, 0)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #geotranformation\n",
    "    trans =  flood_georeferenced.transform\n",
    "    trans*(0,0)  # goes from COL-ROW index to X-Y:  trans*(ncol,nrow)=(x_coordinate,y_coordinate)\n",
    "    \n",
    "    #extract the dimension of the raster\n",
    "    size_equi7_tile = dtm.shape    \n",
    "    n_row, n_col    = size_equi7_tile \n",
    "    \n",
    "    # pixel size in m\n",
    "    L = np.abs(np.array(trans*(0,1))[1]-np.array(trans*(0,0))[1])  \n",
    "     \n",
    "          \n",
    "    #local slope\n",
    "    slope_max =  np.gradient( dtm, L)\n",
    "    slope_max =  np.sqrt(slope_max[0]**2 + slope_max[1]**2 )   \n",
    "    \n",
    "    slope_steep   =   np.array(slope_max >  param_threshold_slope).astype('uint8')\n",
    "    \n",
    "    \n",
    "    \n",
    "    #############################################################################\n",
    "    ##connected components anaysis with cv2 - identifies contiguous flooded areas        \n",
    "    #############################################################################\n",
    "    \n",
    "    #makes sure there are no values other than 1 and 0\n",
    "    exclusion[(exclusion !=1) & (exclusion !=0)]                     = 1  \n",
    "    flood[(flood !=1) & (flood !=0)]                                 = 0\n",
    "    obswater[(obswater !=1) & (obswater !=0)]                        = 0\n",
    "    permanent_water[(permanent_water !=1) & (permanent_water !=0)]   = 0\n",
    "    \n",
    "     \n",
    "    \n",
    "    #some kernels \n",
    "    kernel_1       = np.ones((3,3),np.uint8)\n",
    "    kernel_1_cross = np.array([[0, 1, 0], [1, 1, 1], [0, 1, 0]], dtype = np.uint8)\n",
    "    kernel_2       = np.ones((5,5),np.uint8)\n",
    "    \n",
    "    \n",
    "\n",
    "    #runs morphological closing to remove small holes and very irregular borders from flood and obswater\n",
    "    flood    = cv2.morphologyEx(flood   ,    cv2.MORPH_CLOSE, kernel_1_cross,  iterations = 2 )\n",
    "    obswater = cv2.morphologyEx(obswater,    cv2.MORPH_CLOSE, kernel_1_cross,  iterations = 2 )\n",
    "     \n",
    "    #dilate exclusion mask\n",
    "    exclusion = cv2.dilate(exclusion  ,  kernel_1)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    #############################################\n",
    "    #closes small holes in flood map with  cv2 ##\n",
    "    #############################################\n",
    "    print ('Closing small gaps in flood map...')\n",
    "    \n",
    "    threshold_n_pixels = (param_size_gaps_close*1e6 / L**2).astype(int)\n",
    "    \n",
    "    binary_map_complementary_flood               = np.logical_not(flood).astype('uint8')\n",
    "    z_num_labels, z_labels, z_stats, z_centroids = cv2.connectedComponentsWithStats(binary_map_complementary_flood,connectivity=8) \n",
    "\n",
    "    for i in range(len(z_stats)):\n",
    "        if np.abs(z_stats[i,4]) < threshold_n_pixels:\n",
    "            flood    [ z_stats[i,1]: z_stats[i,1] + z_stats[i,3] , z_stats[i,0]:z_stats[i,0] + z_stats[i,2] ] [z_labels[ z_stats[i,1]: z_stats[i,1] + z_stats[i,3] , z_stats[i,0]:z_stats[i,0] + z_stats[i,2] ] ==i] = 1\n",
    "            obswater [ z_stats[i,1]: z_stats[i,1] + z_stats[i,3] , z_stats[i,0]:z_stats[i,0] + z_stats[i,2] ] [z_labels[ z_stats[i,1]: z_stats[i,1] + z_stats[i,3] , z_stats[i,0]:z_stats[i,0] + z_stats[i,2] ] ==i] = 1\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    if os.path.isfile(input_dir / 'permanent_water.tif'):\n",
    "        permanent_water = cv2.morphologyEx(permanent_water,    cv2.MORPH_CLOSE, kernel_1_cross,  iterations = 2 )\n",
    "        \n",
    "    else:\n",
    "        permanent_water = obswater - flood\n",
    "        permanent_water[(permanent_water!=0) & (permanent_water!=1) ] = 0\n",
    "    \n",
    "\n",
    "\n",
    "    # !!!  opencv with connectivity = 4 has problems in some versions of the package better use connectivity = 8 !!!!\n",
    "           \n",
    "    # Applying cv2.connectedComponents() - possibly change the connectivity type \n",
    "    # z_stats contains: [xtop, ytop, xwidth, ywidth, #pixels] - first element of stats correspondes to background value\n",
    "    \n",
    "    z_num_labels, z_labels, z_stats, z_centroids = cv2.connectedComponentsWithStats(flood,connectivity=8)   \n",
    "    \n",
    "      \n",
    "    flood_dilated          =   cv2.dilate(flood  ,  kernel_1)\n",
    "    flood_eroded           =   cv2.erode (flood  ,  kernel_1_cross)\n",
    "    \n",
    "    exclusion_dilated      =   cv2.dilate(exclusion ,  kernel_1)\n",
    "\n",
    "    permanent_water_dilated =   cv2.dilate(permanent_water ,  kernel_1)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    flood_border           =   flood_dilated    - flood_eroded \n",
    "    flood_border_inner     =   flood            - flood_eroded\n",
    "    \n",
    "    \n",
    "    slope_steep_dilated      =   cv2.dilate(slope_steep  ,  kernel_1)\n",
    "    \n",
    "\n",
    "    exclusion_dilated      [ (exclusion       ==0)  & (exclusion_dilated       ==1)  & (flood==0) & (flood_dilated==1)] = 0\n",
    "    permanent_water_dilated[ (permanent_water ==0)  & (permanent_water_dilated ==1)  & (flood==0) & (flood_dilated==1)] = 0\n",
    "    slope_steep_dilated    [ (slope_steep      ==0) & (slope_steep_dilated      ==1) & (flood==0) & (flood_dilated==1)] = 0\n",
    "    \n",
    "    \n",
    "    flood_border          =     flood_border *  np.logical_not( exclusion_dilated )   *  np.logical_not( permanent_water_dilated)   *    np.logical_not(slope_steep_dilated)  \n",
    "    \n",
    "    dtm_border_flood      =   dtm * flood_border\n",
    "      \n",
    "    \n",
    "   \n",
    "    \n",
    "    ## AVERAGES THE DEM ALONG THE BORDER \n",
    "    dtm_border_flood_smooth= convolve ( dtm_border_flood, kernel_2, mask = flood_border == 0, preserve_nan = True )\n",
    "    dtm_border_flood_smooth[flood_border==0] = np.nan     \n",
    "    \n",
    "    \n",
    "    flood_border =   flood_border * flood_border_inner\n",
    "\n",
    "\n",
    "    #######################################################\n",
    "    ## WATER LEVEL ESTIMATION IN INITIALLY FLOODED AREAS ##\n",
    "    #######################################################\n",
    "    \n",
    "    \n",
    "    z_water_level = np.full(size_equi7_tile, np.nan, dtype='float32')\n",
    "    \n",
    "    ROW, COL   =  np.mgrid[0:n_row,0:n_col].astype('uint32')\n",
    "    \n",
    "    row_flood                          =   np.ma.masked_array(ROW,      z_labels==0).compressed()\n",
    "    col_flood                          =   np.ma.masked_array(COL,      z_labels==0).compressed()\n",
    "    flood_labels_compressed            =   np.ma.masked_array(z_labels, z_labels==0).compressed()\n",
    "        \n",
    "    row_flood_border                   =   np.ma.masked_array(ROW,                     flood_border==0).compressed()\n",
    "    col_flood_border                   =   np.ma.masked_array(COL,                     flood_border==0).compressed()        \n",
    "    flood_borders_labels_compressed    =   np.ma.masked_array(z_labels,                flood_border==0).compressed()\n",
    "    dtm_border_flood_smooth_compressed =   np.ma.masked_array(dtm_border_flood_smooth, flood_border==0).compressed()\n",
    "\n",
    "    \n",
    "    #  assigns water levels to initial flooded areas based on the DTM values along the borders\n",
    "    #  of flooded areas that are not contiguous with the exclusion mask\n",
    "\n",
    "     \n",
    "    print('Assigns water elevation to initial flooded areas')\n",
    "    \n",
    "\n",
    "    for i in range (1,len(z_stats)):\n",
    "\n",
    "        temp_position_flood           =  np.stack( ( row_flood[flood_labels_compressed==i],col_flood[flood_labels_compressed==i]),axis = 1)\n",
    "        temp_position_border          =  np.stack( ( row_flood_border[flood_borders_labels_compressed==i],col_flood_border[flood_borders_labels_compressed==i]),axis = 1)\n",
    "        temp_dtm_border_flood_smooth  =  dtm_border_flood_smooth_compressed[flood_borders_labels_compressed==i]\n",
    "        \n",
    "        len_border  = len(temp_position_border)\n",
    " \n",
    "\n",
    "        if  len_border < param_min_flood_size: \n",
    "                \n",
    "            with warnings.catch_warnings():\n",
    "                warnings.filterwarnings('ignore')\n",
    "                z_water_level[temp_position_flood[:,0], temp_position_flood[:,1] ]  =  np.nanquantile(dtm[temp_position_flood[:,0], temp_position_flood[:,1] ], param_inner_quantile)\n",
    "    \n",
    "    \n",
    "        else:   \n",
    "    \n",
    "            \n",
    "\n",
    "            \n",
    "            # Build a cKDTree for each set of points\n",
    "            tree_BORDER = cKDTree(temp_position_border)\n",
    "    \n",
    "            param_workers_cKDTree =  8\n",
    "            distances, indices = tree_BORDER.query(temp_position_flood, k=param_max_number_neighbors,workers = param_workers_cKDTree)\n",
    "\n",
    "            distances = distances.astype('float32')\n",
    "            distances[distances==0]  = 1\n",
    "            indices   = indices.astype('uint32')\n",
    "\n",
    "\n",
    "            if distances.ndim == 1:\n",
    "                distances = np.expand_dims(distances, axis=1)\n",
    "                indices   = np.expand_dims(indices, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "            if param_max_number_neighbors > len_border:\n",
    "                indices   = indices  [:, :len_border]\n",
    "                distances = distances[:, :len_border]\n",
    "\n",
    "\n",
    "            \n",
    "            #####################\n",
    "            #####################\n",
    "            ## choose the weights\n",
    "            #####################\n",
    "            #####################\n",
    "                \n",
    "                \n",
    "            ################################\n",
    "            # inverse distance weighting IDW\n",
    "            ################################\n",
    "                \n",
    "            weights  =   1 / (distances ** param_inverse_dist_exp).astype('float32')\n",
    "\n",
    "                \n",
    "              \n",
    "             ##############################\n",
    "             ##############################\n",
    "             ## choose WL estimation method\n",
    "             ##############################\n",
    "             ##############################\n",
    "\n",
    "\n",
    "            if param_WL_estimation_method == 'method_A':\n",
    "            #METHOD A : water level is interpoleated using IDW or EDW weights\n",
    "                    \n",
    "                \n",
    "                dtm_temp_statistic    =  (np.sum((temp_dtm_border_flood_smooth[indices] * weights).astype('float32'), axis = 1 )  / np.sum( weights , axis = 1 ) ).astype('float32')\n",
    "                \n",
    "                \n",
    "            elif param_WL_estimation_method == 'method_B':\n",
    "                #METHOD B : water level is a distence-weighted QUANTILE of all closest dtm neighboring cells \n",
    "        \n",
    "                    \n",
    "                dtm_temp_statistic    =   weighted_quantile(temp_dtm_border_flood_smooth[indices], param_border_percentile, weights  =  weights)\n",
    "                             \n",
    "                    \n",
    "    \n",
    "    \n",
    "                \n",
    "            z_water_level[temp_position_flood[:,0], temp_position_flood[:,1]]    =    dtm_temp_statistic \n",
    "    \n",
    "    \n",
    "     \n",
    "    \n",
    "\n",
    "    ###############\n",
    "    #################\n",
    "    ##FLOOD EXPANSION\n",
    "    ###################\n",
    "    #####################\n",
    " \n",
    "    if os.path.isfile(exclusion_path) and np.sum(flood)>0: \n",
    "     \n",
    "        \n",
    "        print('Augmenting flooded areas...')\n",
    "        \n",
    "    \n",
    "        param_connectivity                 =  8         # <<INPUT connectivity used to spread flooded areas\n",
    "    \n",
    "         \n",
    "     \n",
    "        z_water_level_masked_compressed         =   np.ma.masked_array(z_water_level, flood_border_inner==0).compressed() \n",
    "        z_water_level_masked_compressed_initial =   np.ma.masked_array(z_water_level, flood_border_inner==0).compressed()\n",
    "        row_flood_border                        =   np.ma.masked_array(ROW,           flood_border_inner==0).compressed()\n",
    "        col_flood_border                        =   np.ma.masked_array(COL,           flood_border_inner==0).compressed()\n",
    "        flood_labels_border                     =   np.ma.masked_array(z_labels,      flood_border_inner==0).compressed()\n",
    "        \n",
    "        FLOOD = np.array ( [flood_labels_border,  row_flood_border,  col_flood_border,  z_water_level_masked_compressed, z_water_level_masked_compressed_initial ]  ).T\n",
    "        \n",
    "        #sorts based on decreasing water elevation\n",
    "        FLOOD_sort_descending= np.flipud(FLOOD[FLOOD[:, 3].argsort()])\n",
    "        \n",
    "        #size of initial flooded areas in m2\n",
    "        dim_flooded_area = z_stats[:,4] * L**2\n",
    "        dim_flooded_area[dim_flooded_area<0]=0  #  prevents potential negative values caused by overflow \n",
    "        \n",
    "        \n",
    "        ########################\n",
    "        # max expansion distance  \n",
    "        ########################\n",
    "       \n",
    "\n",
    "        ##EXPONENTIAL\n",
    "        threshold_distance = param_max_propagation_distance * 1000   *  ( 1 -   pow(2,   -  dim_flooded_area   / (param_distance_range * 1e6  )  )        )\n",
    "        \n",
    "        \n",
    "        #avoids singularities in case no flood expansion is set\n",
    "        threshold_distance = threshold_distance + 1\n",
    "        \n",
    "        \n",
    "            \n",
    "        FLOOD_sort_descending_list= list (FLOOD_sort_descending)\n",
    "          \n",
    "        z_water_level_augmented = np.copy(z_water_level)\n",
    "        \n",
    "        \n",
    "        z_labels_augmented      = np.copy(z_labels)\n",
    "        temp_dist_from_border   = np.zeros(z_labels.shape, dtype = 'float16')\n",
    "        \n",
    "        \n",
    "        \n",
    "        i=0\n",
    "        i_counter  =  len ( FLOOD_sort_descending_list )\n",
    "        i_stop     =  len ( FLOOD_sort_descending_list )\n",
    "        total_processed = 0\n",
    "        \n",
    "        \n",
    "        \n",
    "           \n",
    "        while i < i_counter: \n",
    "            \n",
    "            if i == i_stop:\n",
    "                FLOOD_sort_descending = np.vstack(FLOOD_sort_descending_list)\n",
    "                FLOOD_sort_descending = FLOOD_sort_descending[i_stop: ,:]\n",
    "                FLOOD_sort_descending = np.flipud(FLOOD_sort_descending[FLOOD_sort_descending[:, 3].argsort()]) \n",
    "                FLOOD_sort_descending_list= list (FLOOD_sort_descending)\n",
    "                i=0\n",
    "                i_stop    = len(FLOOD_sort_descending)\n",
    "                i_counter = len(FLOOD_sort_descending) \n",
    "        \n",
    "        \n",
    "            vicini =  ij_neighbors(FLOOD_sort_descending[i,1], FLOOD_sort_descending[i,2] , n_row, n_col, param_connectivity)  \n",
    "             \n",
    "         \n",
    "        \n",
    "            label     = FLOOD_sort_descending[i,0].astype('uint32')\n",
    "            \n",
    "            \n",
    "            initial_wl= FLOOD_sort_descending[i,4]  \n",
    "            \n",
    "    \n",
    "            temp_= ( L +  temp_dist_from_border[FLOOD_sort_descending[i,1].astype('uint32'), FLOOD_sort_descending[i,2].astype('uint32')]  ) / threshold_distance[label]\n",
    "            \n",
    "            wl = (  initial_wl  -  ( initial_wl  - dtm[vicini[:,0],vicini[:,1]]   )  * temp_  )     * np.heaviside(1-temp_ , 0 )   +    dtm[vicini[:,0],vicini[:,1]]  *     (  1- np.heaviside(1-temp_ , 0 )    )\n",
    "           \n",
    "            wl[wl>FLOOD_sort_descending[i,3]] = FLOOD_sort_descending[i,3]\n",
    "            \n",
    "            \n",
    "                                                                                                                    \n",
    "            condition =  (   \n",
    "                \n",
    "                         np.heaviside( (exclusion[vicini[:,0],vicini[:,1]] > 0)  + (obswater[vicini[:,0],vicini[:,1]] > 0) + (permanent_water[vicini[:,0],vicini[:,1]] > 0)   , 0).astype('bool')          # 1. must be in the exlusion or permanent water layer\n",
    "    \n",
    "                       * ( dtm[vicini[:,0],vicini[:,1]] <  (wl-0.01) ) # FLOOD_sort_descending[i,3] #  z_flooded_areas_augmented[i][2]                   # 2. dtm must be lower than the corresponding water level    \n",
    "                     \n",
    "                       * np.heaviside(  np.isnan( z_water_level_augmented[vicini[:,0],vicini[:,1]])         , 0  ).astype('bool')                        # 3. must be nodata (i.e. not alreay assigned)\n",
    "    \n",
    "                         )\n",
    "        \n",
    "           \n",
    "            temp_dist_from_border[vicini[:,0][condition],vicini[:,1][condition]]    = L * np.array([1.414, 1, 1.414, 1, 1.414, 1, 1.414, 1])[condition]     + temp_dist_from_border[FLOOD_sort_descending[i,1].astype('uint32'), FLOOD_sort_descending[i,2].astype('uint32')]\n",
    "            \n",
    "            z_water_level_augmented[vicini[:,0][condition],vicini[:,1][condition]]  =  wl[condition]   \n",
    "            \n",
    "            FLOOD_sort_descending_list.append  (  np.array([ label*(condition[condition]) ,  vicini[:,0][condition],  vicini[:,1][condition]  ,  wl[condition] , initial_wl*(condition[condition])  ]).T  ) \n",
    "            \n",
    "            z_labels_augmented[vicini[:,0][condition],vicini[:,1][condition]]  =  label \n",
    "            \n",
    "            i_counter+= np.sum(condition)\n",
    "                        \n",
    "                                 \n",
    "            i+=1 \n",
    "            \n",
    "            #print(i)\n",
    "            total_processed +=1\n",
    "        \n",
    "    \n",
    "        \n",
    "\n",
    "        ##############################\n",
    "        ## smoothing expanded WL ####\n",
    "        ##############################\n",
    "    \n",
    "         \n",
    "        print('Smoothing... \\n')\n",
    "               \n",
    "        \n",
    "        param_number_smoothings      = 20   #<<<<<<  INPUT\n",
    "        \n",
    "        \n",
    "        z_water_level_augmented_initial = np.copy(z_water_level_augmented)\n",
    "        z_water_level_augmented[ np.isnan(z_water_level_augmented_initial) ] = dtm[  np.isnan(z_water_level_augmented_initial)  ]\n",
    "        \n",
    "        \n",
    "        target_i, target_j  =  np.where( (~np.isnan(z_water_level_augmented_initial)) & (flood == 0) )\n",
    "        target_i = target_i.astype(np.int32) ; target_j = target_j.astype(np.int32)\n",
    "        \n",
    "        \n",
    "        \n",
    "        connectivity = 24      #<<<<<<  INPUT\n",
    "        \n",
    "        \n",
    "        neighbors_i = np.zeros((target_i.shape[0], connectivity)).astype(np.uint32)\n",
    "        neighbors_j = np.zeros((target_i.shape[0], connectivity)).astype(np.uint32)\n",
    "        \n",
    "          \n",
    "        \n",
    "        for i in range(target_i.shape[0]):\n",
    "            \n",
    "            neighbors = ij_neighbors(target_i[i], target_j[i], n_row, n_col, connectivity)\n",
    "            neighbors_i[i, :] = neighbors[:, 0]\n",
    "            neighbors_j[i, :] = neighbors[:, 1]\n",
    "                    \n",
    "        \n",
    "        \n",
    "        mask_1 = np.where(~np.isnan(z_water_level))\n",
    "\n",
    "        \n",
    "        for v in range(param_number_smoothings):\n",
    "            z_water_level_augmented[target_i,target_j] = np.mean(z_water_level_augmented[neighbors_i,neighbors_j], axis = 1 )\n",
    "            \n",
    "            z_water_level_augmented[ mask_1]  = z_water_level[  mask_1  ]\n",
    "        \n",
    "        z_water_level_augmented[ np.isnan(z_water_level_augmented_initial) ] = np.nan\n",
    "        \n",
    "\n",
    "    else:\n",
    "        z_water_level_augmented = np.copy(z_water_level)\n",
    "\n",
    "    \n",
    "\n",
    "     \n",
    "     \n",
    "    ######\n",
    "    # WD #\n",
    "    ######\n",
    "    WD                        = ( ( z_water_level_augmented - dtm ) * 100  ).astype('float32')   \n",
    "    \n",
    "    WD[WD<0] = 0 \n",
    "    WD[WD > 0]                = WD[WD > 0] + param_WD_star\n",
    "    WD[(WD==0) & (flood>0)  ] = param_WD_star\n",
    "    \n",
    "    \n",
    "    \n",
    "    #dummy water depth assigned to permanent water bodies\n",
    "    WD[permanent_water==1] = 9999 \n",
    "    \n",
    "    WD[np.isnan(WD)] = 0\n",
    "\n",
    "    FLEXTH_flood = WD\n",
    "    FLEXTH_flood[WD > 0] = 1 # > 10\n",
    "    FLEXTH_flood[permanent_water==1] = 0\n",
    "    \n",
    "    \n",
    "    ######\n",
    "    # WL #\n",
    "    ######\n",
    " \n",
    "    WL          = ( z_water_level_augmented   ).astype('float32')   \n",
    "    \n",
    "    WL[WD > 0]  = WL[WD > 0] + param_WD_star/100\n",
    "    WL[WD==0 ]  = np.nan\n",
    "    \n",
    "    \n",
    "    \n",
    "    #dummy water level assigned to permanent water bodies\n",
    "    WL[permanent_water==1] = 9999 \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ########\n",
    "    ##SAVING\n",
    "    ########\n",
    "    \n",
    "    print('Saving \\n')\n",
    "    with rasterio.open(\n",
    "       output_dir / f'FLOOD_{param_WL_estimation_method}_Smax_{param_threshold_slope}_Nmax_{param_max_number_neighbors}_a_{param_inverse_dist_exp}_Dmax_{param_max_propagation_distance}_A12_{param_distance_range}_gaps_{param_size_gaps_close}.tif',\n",
    "       mode = \"w\",\n",
    "       driver= \"GTiff\",\n",
    "       height=n_row,\n",
    "       width=n_col,\n",
    "       count=1,\n",
    "       dtype=rasterio.uint16,\n",
    "       crs=flood_georeferenced.crs,\n",
    "       transform=flood_georeferenced.transform\n",
    "       ) as flood_mask:\n",
    "        flood_mask.write(FLEXTH_flood, 1)\n",
    "        \n",
    "    prefix  = os.path.splitext(os.path.basename(flood_path))[0]\n",
    "    \n",
    "    if param_output_map == \"WD\" or  param_output_map == \"WL_WD\" :\n",
    "    \n",
    "        with rasterio.open(\n",
    "            output_dir / f'_WD_{prefix}_{param_WL_estimation_method}_Smax_{param_threshold_slope}_Nmax_{param_max_number_neighbors}_a_{param_inverse_dist_exp}_Dmax_{param_max_propagation_distance}_A12_{param_distance_range}_gaps_{param_size_gaps_close}.tif',\n",
    "            mode=\"w\",\n",
    "            driver=\"GTiff\",\n",
    "            compress='deflate',\n",
    "            height=n_row,\n",
    "            width=n_col,\n",
    "            count=1,\n",
    "            dtype=rasterio.uint16,\n",
    "            crs=flood_georeferenced.crs,\n",
    "            transform=flood_georeferenced.transform,\n",
    "            nodata= 0\n",
    "            ) as water_depth:\n",
    "                water_depth.write(WD, 1)\n",
    "                \n",
    "                \n",
    "    if param_output_map == \"WL\" or  param_output_map == \"WL_WD\" :\n",
    "    \n",
    "        with rasterio.open(\n",
    "            output_dir / f'_WL_{prefix}_{param_WL_estimation_method}_Smax_{param_threshold_slope}_Nmax_{param_max_number_neighbors}_a_{param_inverse_dist_exp}_Dmax_{param_max_propagation_distance}_A12_{param_distance_range}_gaps_{param_size_gaps_close}.tif',\n",
    "            mode=\"w\",\n",
    "            driver=\"GTiff\",\n",
    "            compress='deflate',\n",
    "            height=n_row,\n",
    "            width=n_col,\n",
    "            count=1,\n",
    "            dtype=rasterio.float32,\n",
    "            crs=flood_georeferenced.crs,\n",
    "            transform=flood_georeferenced.transform,\n",
    "            ) as water_level:\n",
    "                water_level.write(WL, 1)\n",
    "    \n",
    "   \n",
    "    \n",
    "    print('Finish \\n')\n",
    "      \n",
    "      \n",
    "    \n",
    "    \n",
    "    flood_georeferenced.close()\n",
    "    \n",
    "\n",
    "        \n",
    "########        \n",
    "## RUN ! \n",
    "########     \n",
    "  \n",
    "   \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    \n",
    "    start = time.time()  \n",
    "    \n",
    "    if param_tiling == True: \n",
    "       \n",
    "        \n",
    "        #tiles all the inputs if param_tile_inputs is True \n",
    "        if param_tile_inputs == True:             \n",
    "            print('Tiling the input rasters...')\n",
    "            \n",
    "            tiling(input_dir / 'flood.tif' , input_dir, param_tile_size)\n",
    "            \n",
    "            tiling(input_dir / 'dtm.tif'   , input_dir, param_tile_size)\n",
    "            \n",
    "            if os.path.isfile(input_dir / 'exclusion.tif'):\n",
    "                tiling(input_dir / 'exclusion.tif' , input_dir, param_tile_size)\n",
    "                \n",
    "            if os.path.isfile(input_dir / 'obswater.tif'):\n",
    "                tiling(input_dir / 'obswater.tif' , input_dir, param_tile_size)\n",
    "                \n",
    "            if os.path.isfile(input_dir / 'permanent_water.tif'):\n",
    "                tiling(input_dir / 'permanent_water.tif' , input_dir, param_tile_size)\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "        input_list_flood = glob.glob( str(input_dir/\"**/*flood_tile*.tif\")  , recursive=True)\n",
    "       \n",
    "        for index, flood_path in enumerate(input_list_flood):\n",
    "            \n",
    "            print(f'Processing tile {index+1} out of {len(input_list_flood)}')\n",
    "            \n",
    "            dtm_path             =  flood_path.replace(\"flood_tile\", \"dtm_tile\") \n",
    "            exclusion_path       =  flood_path.replace(\"flood_tile\", \"exclusion_tile\") \n",
    "            obswater_path        =  flood_path.replace(\"flood_tile\", \"obswater_tile\")  \n",
    "            permanent_water_path =  flood_path.replace(\"flood_tile\", \"permanent_water_tile\") \n",
    "    \n",
    "    \n",
    "            flood_processing(flood_path           = flood_path ,\n",
    "                             dtm_path             = dtm_path  , \n",
    "                             exclusion_path       = exclusion_path ,\n",
    "                             obswater_path        = obswater_path , \n",
    "                             permanent_water_path = permanent_water_path )   \n",
    "\n",
    "       \n",
    "        \n",
    "        \n",
    "    else:\n",
    "        flood_processing(flood_path           = input_dir / 'flood.tif' ,\n",
    "                         dtm_path             = input_dir / 'dtm.tif'   , \n",
    "                         exclusion_path       = input_dir / 'exclusion.tif' ,\n",
    "                         obswater_path        = input_dir / 'obswater.tif' , \n",
    "                         permanent_water_path = input_dir / 'permanent_water.tif' )        \n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "        \n",
    "\n",
    "    end = time.time()\n",
    "    print(f'Total processing time:{int((end - start)/60)} minutes')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef5c7ee-db9a-4859-8c7a-9465ab74b984",
   "metadata": {},
   "source": [
    "# 7. Quick Output Summary\n",
    "Now, in the last step, we calculate the area, flooded initially, before we applied FLEXTH and the area after FLEXTH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "692b43d7-9959-4ce6-8a2a-efbaa0360d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Flooded Area: 47.89km2\n",
      "Flooded Area with FLEXTH: 89.66km2\n"
     ]
    }
   ],
   "source": [
    "# Function to print and calculate statistics on processed flood map\n",
    "def FLEXTH_stats():\n",
    "    with (\n",
    "    rasterio.open(\n",
    "        output_dir / f'FLOOD_{param_WL_estimation_method}_Smax_{param_threshold_slope}_Nmax_{param_max_number_neighbors}_a_{param_inverse_dist_exp}_Dmax_{param_max_propagation_distance}_A12_{param_distance_range}_gaps_{param_size_gaps_close}.tif',\n",
    "            ) as src, # Processed Flood\n",
    "    rasterio.open(\n",
    "        input_dir / 'flood.tif') as src2 # initial flood (S1 and S2)\n",
    "    ):\n",
    "        flexth_rst = src.read(1)\n",
    "        initial_flood = src2.read(1)\n",
    "\n",
    "        pixel_width, pixel_height = src.res  \n",
    "        pixel_area = abs(pixel_width * pixel_height) \n",
    "        \n",
    "        mask = (flexth_rst == 1)\n",
    "        initial_flood_area = (initial_flood == 1)\n",
    "        \n",
    "        count_after = np.sum(mask)\n",
    "        count_before = np.sum(initial_flood_area)\n",
    "        \n",
    "        # Calculate the total area\n",
    "        total_area_after = np.round((count_after * pixel_area) / 1000000, decimals = 2)\n",
    "        total_area_before = np.round((count_before * pixel_area) / 1000000, decimals = 2)\n",
    "                \n",
    "        print(f'Initial Flooded Area: {total_area_before}km2\\nFlooded Area with FLEXTH: {total_area_after}km2')\n",
    "        \n",
    "# Function to output a raster only with the flooded area, not WD\n",
    "# set a nan value in meta data\n",
    "FLEXTH_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5596882f-73d0-4571-8a64-089c71713c4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
